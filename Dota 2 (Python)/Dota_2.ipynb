{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pandas.read_csv('C:/Data_P/Week_7/features_train.csv', index_col=False)\n",
    "y_train = data_train['radiant_win']\n",
    "X_train = data_train.loc[:, 'start_time':'dire_first_ward_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Проверка на наличие пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d5_gold                        97230\n",
       "d5_lh                          97230\n",
       "d5_kills                       97230\n",
       "d5_deaths                      97230\n",
       "d5_items                       97230\n",
       "first_blood_time               77677\n",
       "first_blood_team               77677\n",
       "first_blood_player1            77677\n",
       "first_blood_player2            53243\n",
       "radiant_bottle_time            81539\n",
       "radiant_courier_time           96538\n",
       "radiant_flying_courier_time    69751\n",
       "radiant_tpscroll_count         97230\n",
       "radiant_boots_count            97230\n",
       "radiant_ward_observer_count    97230\n",
       "radiant_ward_sentry_count      97230\n",
       "radiant_first_ward_time        95394\n",
       "dire_bottle_time               81087\n",
       "dire_courier_time              96554\n",
       "dire_flying_courier_time       71132\n",
       "dire_tpscroll_count            97230\n",
       "dire_boots_count               97230\n",
       "dire_ward_observer_count       97230\n",
       "dire_ward_sentry_count         97230\n",
       "dire_first_ward_time           95404\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.count().tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки, в которых имеются пропуски: first_blood_time, first_blood_team, first_blood_player1, first_blood_player2, radiant_bottle_time, radiant_courier_time, radiant_flying_courier_time, radiant_first_ward_time, dire_bottle_time, dire_courier_time, dire_flying_courier_time, dire_first_ward_time.\n",
    "Как видно, имеется как минимум 2 признака, в которых существуют пропуски:\n",
    "  - dire_first_ward_time - пропуски могут объясняться тем, что команда dire в первые 5 минут игры не установила предмет, который позволяет видеть часть игрового поля;\n",
    "  - dire_flying_courier_time - пропуски могут объясняться тем, что команда dire в первые 5 минут игры не приобрела предмет \"flying_courier\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Замена пропусков на нули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d5_gold                        97230\n",
       "d5_lh                          97230\n",
       "d5_kills                       97230\n",
       "d5_deaths                      97230\n",
       "d5_items                       97230\n",
       "first_blood_time               97230\n",
       "first_blood_team               97230\n",
       "first_blood_player1            97230\n",
       "first_blood_player2            97230\n",
       "radiant_bottle_time            97230\n",
       "radiant_courier_time           97230\n",
       "radiant_flying_courier_time    97230\n",
       "radiant_tpscroll_count         97230\n",
       "radiant_boots_count            97230\n",
       "radiant_ward_observer_count    97230\n",
       "radiant_ward_sentry_count      97230\n",
       "radiant_first_ward_time        97230\n",
       "dire_bottle_time               97230\n",
       "dire_courier_time              97230\n",
       "dire_flying_courier_time       97230\n",
       "dire_tpscroll_count            97230\n",
       "dire_boots_count               97230\n",
       "dire_ward_observer_count       97230\n",
       "dire_ward_sentry_count         97230\n",
       "dire_first_ward_time           97230\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.fillna(value=0)\n",
    "X_train.count().tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Зависимая переменная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве зависимой переменной выступает radiant_win из data_train. В первом пункте она была помещена в y_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Обучение градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведен код функции, которая оценивает GBM с различным количеством деревьев в композиции (i * 10), вычисляет ROC_AUC для каждой композиции, а также время выполнения процесса для соответствующего количества деревьев. При оценке качества была использована кросс-валидация по 5 блокам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_GBM(X, y):\n",
    "    ROC_AUC_GBM = pandas.DataFrame(columns=['n_estimators', 'ROC_AUC', 'time']) # Создали таблицу для занесения результатов.\n",
    "    for i in range(1,6):\n",
    "        model_GBM = GradientBoostingClassifier(n_estimators= i * 10, verbose=True, random_state=42) # Модель GBM с гиперпараметрами.\n",
    "        start_time = datetime.datetime.now() # Время начала процесса кросс-валидации.\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42) # Параметры кросс-валидации.\n",
    "        score = cross_val_score(model_GBM, X, y, cv=cv, scoring='roc_auc').mean() # Обучение модели, и оценка ее качества через ROC_AUC с заданными параметрами кросс-валидации.\n",
    "        time = datetime.datetime.now() - start_time # Вычисление времени процесса кросс-валидации.\n",
    "        ROC_AUC_GBM.loc[i] = [i * 10, score, time] # Занесение результатов в таблицу для композиции с текущим количеством деревьев.\n",
    "    return ROC_AUC_GBM # Возвращает таблицу с результатами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя данную функцию, обучим градиентный бустинг по нашей выборке, а также оценим его качество при различном количестве решающих деревьев в композиции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            7.33s\n",
      "         2           1.3730            6.66s\n",
      "         3           1.3679            6.95s\n",
      "         4           1.3633            6.36s\n",
      "         5           1.3588            5.09s\n",
      "         6           1.3541            3.93s\n",
      "         7           1.3497            3.07s\n",
      "         8           1.3456            2.14s\n",
      "         9           1.3415            1.07s\n",
      "        10           1.3376            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786           13.67s\n",
      "         2           1.3732           12.35s\n",
      "         3           1.3681           12.01s\n",
      "         4           1.3638           10.83s\n",
      "         5           1.3589            8.17s\n",
      "         6           1.3546            6.33s\n",
      "         7           1.3501            4.68s\n",
      "         8           1.3458            2.97s\n",
      "         9           1.3419            1.44s\n",
      "        10           1.3381            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           10.13s\n",
      "         2           1.3729            8.10s\n",
      "         3           1.3678            7.95s\n",
      "         4           1.3635            6.58s\n",
      "         5           1.3586            5.44s\n",
      "         6           1.3538            4.57s\n",
      "         7           1.3493            3.56s\n",
      "         8           1.3451            2.27s\n",
      "         9           1.3412            1.10s\n",
      "        10           1.3373            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           12.48s\n",
      "         2           1.3729            9.56s\n",
      "         3           1.3678            9.14s\n",
      "         4           1.3634            8.07s\n",
      "         5           1.3587            6.54s\n",
      "         6           1.3546            4.90s\n",
      "         7           1.3499            3.50s\n",
      "         8           1.3459            2.39s\n",
      "         9           1.3419            1.23s\n",
      "        10           1.3381            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784            8.76s\n",
      "         2           1.3730            7.95s\n",
      "         3           1.3679            9.23s\n",
      "         4           1.3634            8.85s\n",
      "         5           1.3589            7.09s\n",
      "         6           1.3543            5.40s\n",
      "         7           1.3499            4.09s\n",
      "         8           1.3458            2.74s\n",
      "         9           1.3418            1.35s\n",
      "        10           1.3382            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           17.52s\n",
      "         2           1.3730           22.29s\n",
      "         3           1.3679           22.24s\n",
      "         4           1.3633           21.54s\n",
      "         5           1.3588           19.18s\n",
      "         6           1.3541           16.83s\n",
      "         7           1.3497           15.26s\n",
      "         8           1.3456           14.76s\n",
      "         9           1.3415           14.53s\n",
      "        10           1.3376           13.23s\n",
      "        20           1.3079            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786           28.54s\n",
      "         2           1.3732           26.60s\n",
      "         3           1.3681           23.23s\n",
      "         4           1.3638           20.94s\n",
      "         5           1.3589           20.18s\n",
      "         6           1.3546           19.15s\n",
      "         7           1.3501           17.17s\n",
      "         8           1.3458           15.89s\n",
      "         9           1.3419           14.84s\n",
      "        10           1.3381           13.71s\n",
      "        20           1.3077            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           27.27s\n",
      "         2           1.3729           26.57s\n",
      "         3           1.3678           26.45s\n",
      "         4           1.3635           23.80s\n",
      "         5           1.3586           20.83s\n",
      "         6           1.3538           19.20s\n",
      "         7           1.3493           18.43s\n",
      "         8           1.3451           17.52s\n",
      "         9           1.3412           15.92s\n",
      "        10           1.3373           14.13s\n",
      "        20           1.3072            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           28.61s\n",
      "         2           1.3729           27.22s\n",
      "         3           1.3678           23.49s\n",
      "         4           1.3634           20.43s\n",
      "         5           1.3587           19.24s\n",
      "         6           1.3546           19.41s\n",
      "         7           1.3499           18.47s\n",
      "         8           1.3459           16.63s\n",
      "         9           1.3419           14.97s\n",
      "        10           1.3381           13.99s\n",
      "        20           1.3084            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           30.44s\n",
      "         2           1.3730           27.80s\n",
      "         3           1.3679           22.92s\n",
      "         4           1.3634           21.89s\n",
      "         5           1.3589           21.81s\n",
      "         6           1.3543           20.05s\n",
      "         7           1.3499           17.50s\n",
      "         8           1.3458           16.33s\n",
      "         9           1.3418           15.32s\n",
      "        10           1.3382           13.81s\n",
      "        20           1.3085            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           33.18s\n",
      "         2           1.3730           28.24s\n",
      "         3           1.3679           30.57s\n",
      "         4           1.3633           33.53s\n",
      "         5           1.3588           35.06s\n",
      "         6           1.3541           34.43s\n",
      "         7           1.3497           31.23s\n",
      "         8           1.3456           28.87s\n",
      "         9           1.3415           28.11s\n",
      "        10           1.3376           27.18s\n",
      "        20           1.3079           14.18s\n",
      "        30           1.2877            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786           41.78s\n",
      "         2           1.3732           32.15s\n",
      "         3           1.3681           27.77s\n",
      "         4           1.3638           28.42s\n",
      "         5           1.3589           29.43s\n",
      "         6           1.3546           29.39s\n",
      "         7           1.3501           28.22s\n",
      "         8           1.3458           26.29s\n",
      "         9           1.3419           26.06s\n",
      "        10           1.3381           25.32s\n",
      "        20           1.3077           12.73s\n",
      "        30           1.2871            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           40.49s\n",
      "         2           1.3729           30.57s\n",
      "         3           1.3678           31.18s\n",
      "         4           1.3635           31.52s\n",
      "         5           1.3586           29.41s\n",
      "         6           1.3538           27.50s\n",
      "         7           1.3493           27.17s\n",
      "         8           1.3451           26.35s\n",
      "         9           1.3412           24.22s\n",
      "        10           1.3373           23.37s\n",
      "        20           1.3072           11.80s\n",
      "        30           1.2868            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           23.10s\n",
      "         2           1.3729           23.81s\n",
      "         3           1.3678           27.93s\n",
      "         4           1.3634           29.21s\n",
      "         5           1.3587           26.47s\n",
      "         6           1.3546           26.04s\n",
      "         7           1.3499           26.06s\n",
      "         8           1.3459           25.01s\n",
      "         9           1.3419           23.06s\n",
      "        10           1.3381           21.46s\n",
      "        20           1.3084           11.53s\n",
      "        30           1.2884            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           39.93s\n",
      "         2           1.3730           37.74s\n",
      "         3           1.3679           31.43s\n",
      "         4           1.3634           31.24s\n",
      "         5           1.3589           31.23s\n",
      "         6           1.3543           29.11s\n",
      "         7           1.3499           27.59s\n",
      "         8           1.3458           26.94s\n",
      "         9           1.3418           25.64s\n",
      "        10           1.3382           23.57s\n",
      "        20           1.3085           11.37s\n",
      "        30           1.2885            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           46.36s\n",
      "         2           1.3730           48.96s\n",
      "         3           1.3679           46.83s\n",
      "         4           1.3633           41.20s\n",
      "         5           1.3588           38.82s\n",
      "         6           1.3541           45.06s\n",
      "         7           1.3497           48.25s\n",
      "         8           1.3456           52.35s\n",
      "         9           1.3415           55.52s\n",
      "        10           1.3376           56.33s\n",
      "        20           1.3079           41.07s\n",
      "        30           1.2877           18.85s\n",
      "        40           1.2727            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786            1.06m\n",
      "         2           1.3732            1.02m\n",
      "         3           1.3681           53.92s\n",
      "         4           1.3638           53.30s\n",
      "         5           1.3589           52.59s\n",
      "         6           1.3546           51.52s\n",
      "         7           1.3501           49.72s\n",
      "         8           1.3458           47.10s\n",
      "         9           1.3419           46.89s\n",
      "        10           1.3381           45.55s\n",
      "        20           1.3077           27.87s\n",
      "        30           1.2871           15.38s\n",
      "        40           1.2729            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           38.58s\n",
      "         2           1.3729           41.95s\n",
      "         3           1.3678           45.04s\n",
      "         4           1.3635           46.72s\n",
      "         5           1.3586           43.10s\n",
      "         6           1.3538           39.92s\n",
      "         7           1.3493           39.27s\n",
      "         8           1.3451           39.41s\n",
      "         9           1.3412           40.08s\n",
      "        10           1.3373           40.95s\n",
      "        20           1.3072           26.44s\n",
      "        30           1.2868           13.59s\n",
      "        40           1.2721            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            1.24m\n",
      "         2           1.3729            1.09m\n",
      "         3           1.3678           54.26s\n",
      "         4           1.3634           48.17s\n",
      "         5           1.3587           48.08s\n",
      "         6           1.3546           47.57s\n",
      "         7           1.3499           46.94s\n",
      "         8           1.3459           45.72s\n",
      "         9           1.3419           42.14s\n",
      "        10           1.3381           39.17s\n",
      "        20           1.3084           29.01s\n",
      "        30           1.2884           14.07s\n",
      "        40           1.2738            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784            1.06m\n",
      "         2           1.3730           59.83s\n",
      "         3           1.3679           51.39s\n",
      "         4           1.3634           48.25s\n",
      "         5           1.3589           48.41s\n",
      "         6           1.3543           48.55s\n",
      "         7           1.3499           47.65s\n",
      "         8           1.3458           44.97s\n",
      "         9           1.3418           41.91s\n",
      "        10           1.3382           39.96s\n",
      "        20           1.3085           25.80s\n",
      "        30           1.2885           12.64s\n",
      "        40           1.2737            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785            1.23m\n",
      "         2           1.3730            1.24m\n",
      "         3           1.3679            1.10m\n",
      "         4           1.3633           58.28s\n",
      "         5           1.3588           54.70s\n",
      "         6           1.3541           56.28s\n",
      "         7           1.3497           57.31s\n",
      "         8           1.3456           56.87s\n",
      "         9           1.3415           53.19s\n",
      "        10           1.3376           52.58s\n",
      "        20           1.3079           40.40s\n",
      "        30           1.2877           29.78s\n",
      "        40           1.2727           14.73s\n",
      "        50           1.2613            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3786            1.29m\n",
      "         2           1.3732            1.23m\n",
      "         3           1.3681            1.19m\n",
      "         4           1.3638            1.08m\n",
      "         5           1.3589           58.58s\n",
      "         6           1.3546           55.41s\n",
      "         7           1.3501           55.24s\n",
      "         8           1.3458           54.54s\n",
      "         9           1.3419           54.42s\n",
      "        10           1.3381           51.70s\n",
      "        20           1.3077           41.48s\n",
      "        30           1.2871           27.45s\n",
      "        40           1.2729           13.37s\n",
      "        50           1.2615            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784            1.21m\n",
      "         2           1.3729           58.32s\n",
      "         3           1.3678           59.07s\n",
      "         4           1.3635            1.01m\n",
      "         5           1.3586            1.01m\n",
      "         6           1.3538           55.28s\n",
      "         7           1.3493           54.76s\n",
      "         8           1.3451           54.99s\n",
      "         9           1.3412           54.30s\n",
      "        10           1.3373           51.75s\n",
      "        20           1.3072           39.40s\n",
      "        30           1.2868           26.52s\n",
      "        40           1.2721           13.32s\n",
      "        50           1.2608            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3785           57.27s\n",
      "         2           1.3729            1.19m\n",
      "         3           1.3678            1.23m\n",
      "         4           1.3634            1.22m\n",
      "         5           1.3587            1.14m\n",
      "         6           1.3546            1.05m\n",
      "         7           1.3499            1.01m\n",
      "         8           1.3459            1.01m\n",
      "         9           1.3419           59.82s\n",
      "        10           1.3381           59.53s\n",
      "        20           1.3084           42.31s\n",
      "        30           1.2884           26.44s\n",
      "        40           1.2738           12.91s\n",
      "        50           1.2626            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3784           38.95s\n",
      "         2           1.3730           44.88s\n",
      "         3           1.3679           51.00s\n",
      "         4           1.3634           53.61s\n",
      "         5           1.3589           51.52s\n",
      "         6           1.3543           49.09s\n",
      "         7           1.3499           49.88s\n",
      "         8           1.3458           50.36s\n",
      "         9           1.3418           48.79s\n",
      "        10           1.3382           46.46s\n",
      "        20           1.3085           35.04s\n",
      "        30           1.2885           23.33s\n",
      "        40           1.2737           11.60s\n",
      "        50           1.2624            0.00s\n"
     ]
    }
   ],
   "source": [
    "ROC_AUC_GBM = cross_GBM(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.664851</td>\n",
       "      <td>00:01:04.332237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.682462</td>\n",
       "      <td>00:02:24.632957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>00:03:09.334753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0.694039</td>\n",
       "      <td>00:04:59.388477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.697494</td>\n",
       "      <td>00:05:29.757229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_estimators   ROC_AUC            time\n",
       "1           10  0.664851 00:01:04.332237\n",
       "2           20  0.682462 00:02:24.632957\n",
       "3           30  0.690006 00:03:09.334753\n",
       "4           40  0.694039 00:04:59.388477\n",
       "5           50  0.697494 00:05:29.757229"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC_AUC_GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из таблицы, оптимум при количестве деревьев, равное 30, достигнут не был. При n_estimators = 30 ROC_AUC = 0.69, в то время как при n_estimators = 50 ROC_AUC = 0.697494. При этом есть предположение, с ростом числа деревьев качество будет расти (если судить о том, что при переходе с 30 к 40 и с 40 к 50 ROC_AUC растет). Так как качество растет, то имеет смысл и дальше увеличивать количество деревьев. Но затраты времени на кросс-валидацию существенны: для 30 деревьев затраты времени составили 3 минуты 10 секунд. И с ростом числа деревьев затраты времени также растут. Стоит отметить, что для ускорения обучения можно использовать не всю выборку, а какую то ее часть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Нормализация признаков и оценка логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку линейные алгоритмы чувствительны к масштабу признаков, последние были нормализованы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard = pandas.DataFrame(StandardScaler().fit_transform(X_train), index=X_train.index, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведен код функции, которая оценивает логистичекую регрессию с различными параметрами L-2 регуляризации (параметры C), вычисляет ROC_AUC для каждого параметра, а также время выполнения процесса для соответствующего значения C. При оценке качества была использована кросс-валидация по 5 блокам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_logit(X, y):\n",
    "    ROC_AUC_logit = pandas.DataFrame(columns=['C', 'ROC_AUC', 'time']) # Создали таблицу для занесения результатов.\n",
    "    for i in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        model_logit = LogisticRegression(C=i, random_state=42) # Модель logit с параметрами.\n",
    "        start_time = datetime.datetime.now() # Время начала процесса кросс-валидации.\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42) # Параметры кросс-валидации.\n",
    "        score = cross_val_score(model_logit, X, y, cv=cv, scoring='roc_auc').mean() # Обучение модели, и оценка ее качества через ROC_AUC с заданными параметрами кросс-валидации.\n",
    "        time = datetime.datetime.now() - start_time # Вычисление времени процесса кросс-валидации.\n",
    "        ROC_AUC_logit.loc[i] = [i, score, time] # Занесение результатов в таблицу для текущего значения C.\n",
    "    return ROC_AUC_logit # Возвращает таблицу с результатами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлена таблица с оценкой качества логистических регрессий с различными параметрами регуляризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_AUC_logit = cross_logit(X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.711352</td>\n",
       "      <td>00:00:01.602573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.716363</td>\n",
       "      <td>00:00:02.526169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.716550</td>\n",
       "      <td>00:00:03.476163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.716527</td>\n",
       "      <td>00:00:04.039350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.716522</td>\n",
       "      <td>00:00:03.441895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.716522</td>\n",
       "      <td>00:00:03.813087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.716522</td>\n",
       "      <td>00:00:04.775225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.716522</td>\n",
       "      <td>00:00:05.115544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   C   ROC_AUC            time\n",
       "0.0001        0.0001  0.711352 00:00:01.602573\n",
       "0.0010        0.0010  0.716363 00:00:02.526169\n",
       "0.0100        0.0100  0.716550 00:00:03.476163\n",
       "0.1000        0.1000  0.716527 00:00:04.039350\n",
       "1.0000        1.0000  0.716522 00:00:03.441895\n",
       "10.0000      10.0000  0.716522 00:00:03.813087\n",
       "100.0000    100.0000  0.716522 00:00:04.775225\n",
       "1000.0000  1000.0000  0.716522 00:00:05.115544"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC_AUC_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из таблицы видно, что наибольшее значение ROC_AUC достигается при C = 0.1 (0.716527). Кроме того, скорость оценки в этом случае гораздо быстрее (4 секунды), чем в градиентном бустинге для 30 деревьев (3 минуты 10 секунд), а значение ROC_AUC выше. Это может объясняться тем, что связь между признаками и зависимой является линейной, а значит - вполне подойдет линейный алгоритм (логит), который будет давать качество не хуже нелинейного (градиентного бустинга), при этом будет быстрее обучаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Оценка логистической регресси по выборке без категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку в выобрке имеются категориальные признаки, а используются они как числовые, полезно было бы их выкинуть и снова оценить логистические регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_standard = X_train_standard.drop(['lobby_type' ,'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_AUC_logit_cat = cross_logit(X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.711333</td>\n",
       "      <td>00:00:02.597789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.716376</td>\n",
       "      <td>00:00:04.350406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.716559</td>\n",
       "      <td>00:00:05.215942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.716534</td>\n",
       "      <td>00:00:05.669224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.716530</td>\n",
       "      <td>00:00:05.628890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.716531</td>\n",
       "      <td>00:00:05.607269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.716530</td>\n",
       "      <td>00:00:05.611569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.716530</td>\n",
       "      <td>00:00:05.642291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   C   ROC_AUC            time\n",
       "0.0001        0.0001  0.711333 00:00:02.597789\n",
       "0.0010        0.0010  0.716376 00:00:04.350406\n",
       "0.0100        0.0100  0.716559 00:00:05.215942\n",
       "0.1000        0.1000  0.716534 00:00:05.669224\n",
       "1.0000        1.0000  0.716530 00:00:05.628890\n",
       "10.0000      10.0000  0.716531 00:00:05.607269\n",
       "100.0000    100.0000  0.716530 00:00:05.611569\n",
       "1000.0000  1000.0000  0.716530 00:00:05.642291"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC_AUC_logit_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из таблицы, наибольшее значение ROC_AUC достигается при C = 0.01 (0.716559). При этом, качество текущей модели выше, чем в случае, когда модель оценивается по выборке с категориальными переменными. Это связано с тем, что в предыдущем случае категориальные признаки считались как числовые, что создавало определенные шумы и искажения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Герои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем количество уникальных героев в выборке, а также их возможное максимальное количество по максимальному id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_hero = X_train.loc[:, ['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "hero = X_train_hero.stack() # Сложили столбцы в строки.\n",
    "len(hero.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в нашей выборке 108 уникальных героев, а максимальный id героя - 112."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Создание мешка слов и добавление перекодированных категориальных признаков к числовым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick = numpy.zeros((data_train.shape[0], 112))\n",
    "for i, match_id in enumerate(data_train.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data_train.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data_train.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "X_train_end = pandas.concat([X_train_standard, pandas.DataFrame(X_pick)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Оценивание логистической регрессии по выборке с перекодированными категориальными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "ROC_AUC_logit_end = cross_logit(X_train_end, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.725038</td>\n",
       "      <td>00:00:02.926063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.746333</td>\n",
       "      <td>00:00:05.126191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.751739</td>\n",
       "      <td>00:00:09.418860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.751946</td>\n",
       "      <td>00:00:14.362904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.751927</td>\n",
       "      <td>00:00:12.516947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0000</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>00:00:14.437697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0000</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>00:00:13.872602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0000</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.751922</td>\n",
       "      <td>00:00:15.201348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   C   ROC_AUC            time\n",
       "0.0001        0.0001  0.725038 00:00:02.926063\n",
       "0.0010        0.0010  0.746333 00:00:05.126191\n",
       "0.0100        0.0100  0.751739 00:00:09.418860\n",
       "0.1000        0.1000  0.751946 00:00:14.362904\n",
       "1.0000        1.0000  0.751927 00:00:12.516947\n",
       "10.0000      10.0000  0.751926 00:00:14.437697\n",
       "100.0000    100.0000  0.751923 00:00:13.872602\n",
       "1000.0000  1000.0000  0.751922 00:00:15.201348"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC_AUC_logit_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из таблицы, наибольшее значение ROC_AUC достигается при C = 0.1 (0.751946). Результат существенно улучшился. Это объясняется правильным включением категориальных признаков в обучаемую выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Предсказание вероятностей по тестовой выборке с помощью лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим тестовую выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pandas.read_csv('C:/Data_P/Week_7/features_test.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку лучшей моделью оказалась логистическая регрессия с параметром регуляризации C = 0.1 и оцененной по выборке с перекодированными категориальными признаками, нам необходимо осуществить обработку данных и для тестовой выборки. Другими словами, наобходимо заменить пропуски на нули, а также перекодировать категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test.loc[:, 'start_time':'dire_first_ward_time']\n",
    "X_test = X_test.fillna(value=0)\n",
    "X_test_standard = pandas.DataFrame(StandardScaler().fit_transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "X_test_standard = X_test_standard.drop(['lobby_type' ,'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis = 1)\n",
    "X_test_hero = X_test.loc[:, ['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']]\n",
    "hero_test = X_test_hero.stack()\n",
    "X_pick_test = numpy.zeros((data_test.shape[0], max(hero_test)))\n",
    "for i_test, match_id_test in enumerate(data_test.index):\n",
    "    for p_test in range(5):\n",
    "        X_pick_test[i_test, data_test.loc[match_id_test, 'r%d_hero' % (p_test+1)]-1] = 1\n",
    "        X_pick_test[i_test, data_test.loc[match_id_test, 'd%d_hero' % (p_test+1)]-1] = -1\n",
    "X_test_end = pandas.concat([X_test_standard, pandas.DataFrame(X_pick_test)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test_end содержит в себе тестовую выборку с готовыми данными. Предскажем с помощью логистической регрессии с C = 0.1 вероятности победы команды Rediant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umche\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, random_state=42)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = LogisticRegression(C=0.1, random_state=42)\n",
    "model_best.fit(X_train_end, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model_best.predict_proba(X_test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17539783, 0.82460217],\n",
       "       [0.24271956, 0.75728044],\n",
       "       [0.81248568, 0.18751432],\n",
       "       ...,\n",
       "       [0.76589828, 0.23410172],\n",
       "       [0.37526772, 0.62473228],\n",
       "       [0.57281178, 0.42718822]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, вероятности от наблюдения к наблюдению отличаются. Другими словами, модель не является константной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17539782679878269"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y_pred_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246021732012173"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_pred_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказанные вероятности адекватны, поскольку минимальное и максимальное значение находятся в диапазоне [0:1]. И, соответственно, их сумма равна 1 по определению."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
